{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slavatlsn/slavatlsn.github.io/blob/main/homeworks/hw01_classification/02_hw_fmnist_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Классификация FashionMNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oE1uEalYsoId"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "\n",
        "def parse_pytorch_model(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_info = {}\n",
        "        layer_name, params = layer_str.split(\"(\", 1)\n",
        "        params = params.rstrip(\")\")\n",
        "        layer_info[\"type\"] = layer_name.strip()\n",
        "        param_dict = {}\n",
        "        for param in params.split(\", \"):\n",
        "            if \"=\" in param:\n",
        "                key, value = param.split(\"=\")\n",
        "                param_dict[key.strip()] = eval(value.strip())\n",
        "            else:\n",
        "                param_dict[param.strip()] = None\n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    model_dict = {}\n",
        "    lines = model_str.splitlines()\n",
        "    model_name = lines[0].strip(\"()\")\n",
        "    model_dict[\"model_name\"] = model_name\n",
        "    model_dict[\"layers\"] = []\n",
        "\n",
        "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
        "    for line in lines[1:]:\n",
        "        line = line.strip()\n",
        "        match = layer_regex.match(line)\n",
        "        if match:\n",
        "            index, layer = match.groups()\n",
        "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
        "    return model_dict\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B4Y9NmhesoIe"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxFdVwsTsoIf"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDaaQq6LsoIg",
        "outputId": "fc13f12b-fda3-468e-a1c7-aefd964415f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-11 09:57:25--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-11 09:57:25--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-04-11 09:57:26 (94.0 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U9yIryU9soIh"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UYmRvgcZsoIj"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "aYcL28OsgSq8",
        "outputId": "926e43ae-799f-421e-95ca-2f10727a42b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 10.7MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 200kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.69MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 11.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 6')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAALTJJREFUeJzt3Xt0VOW9//HPZJJM7gkh5AYhhotgBbGlilQLKCjEekG0qHS1YFupNngEvK20VcS2psVT6tGirt+pJe0SpfVU4ehqqRgFagVaUESXlXIJAibhkpILuWfm+f3BYo4jAX22SZ4kvF9rzVqZPfub55mdPfPJzt75js8YYwQAQDeLcj0BAMCZiQACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACutnevXvl8/lUWlpqXfvggw/K5/PpyJEjnTafOXPm6Kyzzuq07wd8VgQQepTS0lL5fD5t2bLF9VRgob6+Xvfee68KCgoUCAQ0cOBA3XDDDWpsbHQ9NfRg0a4nAKB3q62t1cSJE3XgwAHNnTtXw4YN0+HDh/XXv/5VLS0tSkhIcD1F9FAEEIDPpbi4WB9++KHeeustFRQUhJffd999DmeF3oA/waHHmzNnjpKSkrRv3z5dddVVSkpK0sCBA7Vs2TJJ0rvvvqvLLrtMiYmJys/P17PPPhtR/+9//1t33323Ro8eraSkJKWkpKiwsFDvvPPOSWN9+OGHuuaaa5SYmKjMzEwtWLBAf/nLX+Tz+bRu3bqIdTdv3qxp06YpNTVVCQkJmjhxov72t795eo7bt2/XnDlzNGTIEMXFxSk7O1vf/va3VV1d3eH6R44c0cyZM5WSkqL+/fvrzjvvVHNz80nrPfPMMxo7dqzi4+OVnp6um266Sfv37//U+VRWVuqDDz5QW1vbaderqanR8uXLNXfuXBUUFKi1tVUtLS2f7UnjjEcAoVcIBoMqLCxUXl6elixZorPOOkvz5s1TaWmppk2bpi9/+cv6+c9/ruTkZH3rW99SeXl5uHbPnj1atWqVrrrqKi1dulT33HOP3n33XU2cOFEVFRXh9RoaGnTZZZfp1Vdf1X/8x3/ohz/8od58880Of5N/7bXXNGHCBNXV1WnRokV6+OGHVVNTo8suu0x///vfrZ/f2rVrtWfPHt1yyy16/PHHddNNN2nlypW68sor1dEnpsycOVPNzc0qKSnRlVdeqccee0xz586NWOenP/2pvvWtb2n48OFaunSp5s+fr7KyMk2YMEE1NTWnnU9xcbHOOeccffTRR6dd74033lBzc7OGDRumG264QQkJCYqPj9fFF1+sbdu22W4GnGkM0IMsX77cSDL/+Mc/wstmz55tJJmHH344vOzo0aMmPj7e+Hw+s3LlyvDyDz74wEgyixYtCi9rbm42wWAwYpzy8nITCATMQw89FF72i1/8wkgyq1atCi9ramoyI0eONJLM66+/bowxJhQKmeHDh5upU6eaUCgUXrexsdEUFBSYyy+//LTPsby83Egyy5cvj6j9pOeee85IMhs2bAgvW7RokZFkrrnmmoh1v//97xtJ5p133jHGGLN3717j9/vNT3/604j13n33XRMdHR2xfPbs2SY/Pz9ivRPbvLy8/LTPZenSpUaS6d+/v7nwwgvNihUrzBNPPGGysrJMv379TEVFxWnrcWbjCAi9xne/+93w12lpaRoxYoQSExM1c+bM8PIRI0YoLS1Ne/bsCS8LBAKKijq+qweDQVVXVyspKUkjRozQW2+9FV5vzZo1GjhwoK655prwsri4ON16660R89i2bZt27typWbNmqbq6WkeOHNGRI0fU0NCgyZMna8OGDQqFQlbPLT4+Pvx1c3Ozjhw5oosuukiSIuZ4QlFRUcT9O+64Q5L0pz/9SZL0wgsvKBQKaebMmeH5HTlyRNnZ2Ro+fLhef/31086ntLRUxphPvTz72LFjkiSfz6eysjLNmjVLt99+u1atWqWjR4+G/0wKdISLENArxMXFacCAARHLUlNTNWjQIPl8vpOWHz16NHw/FArpv/7rv/TEE0+ovLxcwWAw/Fj//v3DX3/44YcaOnToSd9v2LBhEfd37twpSZo9e/Yp51tbW6t+/fp9xmd3/DzV4sWLtXLlSh06dOik7/VJw4cPj7g/dOhQRUVFae/eveE5GmNOWu+EmJiYzzy30zkRnFdffbWSkpLCyy+66CIVFBTozTff7JRx0DcRQOgV/H6/1XLzsfMmDz/8sO6//359+9vf1o9//GOlp6crKipK8+fPtz5SkRSueeSRR3T++ed3uM7H34w/i5kzZ+rNN9/UPffco/PPP19JSUkKhUKaNm3aZ5rjJ0MzFArJ5/Ppz3/+c4fbyHZ+p5KbmytJysrKOumxzMzMiF8EgE8igNDn/c///I8uvfRSPf300xHLa2pqlJGREb6fn5+v999/X8aYiDf0Xbt2RdQNHTpUkpSSkqIpU6Z87vkdPXpUZWVlWrx4sR544IHw8hNHWh3ZuXNnxCXPu3btUigUCv/JbOjQoTLGqKCgQGefffbnnuOpjB07VpI6vFihoqJCI0eO7LKx0ftxDgh9nt/vP+lKsueff/6kN82pU6fqo48+0v/+7/+GlzU3N+u///u/I9YbO3ashg4dqv/8z/8MnwP5uMOHD1vPT9JJc3z00UdPWfPJcyuPP/64JKmwsFCSNGPGDPn9fi1evPik72uMOeXl3Sd81suwR4wYoTFjxmj16tUR7YFeeeUV7d+/X5dffvlp63Fm4wgIfd5VV12lhx56SLfccou+8pWv6N1339WKFSs0ZMiQiPW+973v6Ve/+pVuvvlm3XnnncrJydGKFSsUFxcn6f/+zBUVFaVf//rXKiws1LnnnqtbbrlFAwcO1EcffaTXX39dKSkpeumllz7z/FJSUjRhwgQtWbJEbW1tGjhwoF555ZWIS8k/qby8XNdcc42mTZumjRs36plnntGsWbM0ZswYScePgH7yk5+ouLhYe/fu1fTp05WcnKzy8nK9+OKLmjt3ru6+++5Tfv/i4mL99re/VXl5+adeiPDLX/5Sl19+uS655BJ973vfU21trZYuXaqzzz5bt99++2feDjgDObv+DujAqS7DTkxMPGndiRMnmnPPPfek5fn5+eZrX/ta+H5zc7O56667TE5OjomPjzcXX3yx2bhxo5k4caKZOHFiRO2ePXvM1772NRMfH28GDBhg7rrrLvPHP/7RSDKbNm2KWPftt982M2bMMP379zeBQMDk5+ebmTNnmrKystM+x44uwz5w4IC57rrrTFpamklNTTVf//rXTUVFxUmXlJ+4DPv99983N9xwg0lOTjb9+vUz8+bNM01NTSeN9cc//tFccsklJjEx0SQmJpqRI0eaoqIis2PHjojt6/Uy7BPWrl1rLrroIhMXF2fS09PNN7/5TVNZWfmZanHm8hnTwX+5AQh79NFHtWDBAh04cEADBw50PR2gzyCAgI9pamo66X9yvvjFLyoYDOpf//qXw5kBfQ/ngICPmTFjhgYPHqzzzz9ftbW1euaZZ/TBBx9oxYoVrqcG9DkEEPAxU6dO1a9//WutWLFCwWBQX/jCF7Ry5UrdeOONrqcG9Dn8CQ4A4AT/BwQAcIIAAgA40ePOAYVCIVVUVCg5Ofmk/lYAgJ7PGKP6+nrl5uaGO9F3pMcFUEVFhfLy8lxPAwDwOe3fv1+DBg065eM9LoCSk5MlSZfoSkWrc1rGdzovR2Zc69GtouICnuru8fBppk8fmmBdU16bbl2Tl1JjXbMge611jSQtGv1lT3XdwsPrzxcb62ko09rqoYjXerva9Ib+FH4/P5UuC6Bly5bpkUceUVVVlcaMGaPHH39cF1544afWnfizW7RiFO3rQwEkdsruFOXz9oaTmGx/WjSmwX4sf7t9QMYk2o+T5OH5SOq5rz3JWwB5fD7G5+V1y2v9xCb4tNMoXXIRwu9//3stXLhQixYt0ltvvaUxY8Zo6tSpJ33QFgDgzNUlAbR06VLdeuutuuWWW/SFL3xBTz31lBISEvSb3/ymK4YDAPRCnR5Ara2t2rp1a8QHdUVFRWnKlCnauHHjSeu3tLSorq4u4gYA6Ps6PYCOHDmiYDB40kf0ZmVlqaqq6qT1S0pKlJqaGr5xBRwAnBmc/yNqcXGxamtrw7f9+/e7nhIAoBt0+lVwGRkZ8vv9OnjwYMTygwcPKjs7+6T1A4GAAgFvl8wCAHqvTj8Cio2N1dixY1VWVhZeFgqFVFZWpvHjx3f2cACAXqpL/g9o4cKFmj17tr785S/rwgsv1KOPPqqGhgbdcsstXTEcAKAX6pIAuvHGG3X48GE98MADqqqq0vnnn681a9acdGECAODM1eM+D6iurk6pqamapGt79n9jd4fuasbajbuAPyXFumbHg1+wrlk+/SnrGkn6f1WTrGv21tm31TFPD7Cumb7oVeuad+q8XVV64FiadU3cD5Ksa8yW96xruhVttzxpN21ap9Wqra1Vymle886vggMAnJkIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4ATNSCHfF8/1VLfvh93TLHVk5sFPX+kT2o3f01h7qvtb1/ijQtY1be328wv+M9m6xn9OvXWNJI3KrrSuKUistq55fvuXrGti98ZZ1wz51U7rGkkKHj7sqc5aH2t6SjNSAECPRgABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBPRridwpvBF229q095uXXN09njrmpbraqxrJClqYz/rmsBR+w6+24fbd4EeNnafdY0kxce2WdfcMew165rLEvZa13w3/UbrmmOtAesaSTrakmBds/O5EdY1qR6aQNcOt+8+vvfJLPuBJGX/v3zrmphXtljX+Pz23dG9vD/0NBwBAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATNCP1wmffQdEEg10wkZNF3XjYuqbuI/umopKU86F9U8i6s+x/54lutC5RTXO8fZGk6t3p1jU/2zjTuuYXFxy1rmlstG8sOjznkHWNJH3wfp51zYA6+0azLf3sX0vDft9kXbN7ZpJ1jSSVz7Rv+Hn2K/bjeGos6uF96Phg9j+nrsIREADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QTNSD3x+v3WNl2aD0dlZ1jWHyvtb1yjeW6PUpgz7319C9ptOAfu+nar/a6Z9kaTscvsGqw3Z9uN4aQc56Hcx1jWHc/M9jCT18/DOcGyQfXPMuGr7LVExIdG6JqrFWwNO4+G1fuzr46xrkp7fbF3TF3AEBABwggACADjR6QH04IMPyufzRdxGjhzZ2cMAAHq5LjkHdO655+rVV1/9v0GiOdUEAIjUJckQHR2t7GwPZ2YBAGeMLjkHtHPnTuXm5mrIkCH6xje+oX379p1y3ZaWFtXV1UXcAAB9X6cH0Lhx41RaWqo1a9boySefVHl5ub761a+qvr6+w/VLSkqUmpoavuXl2X8WPQCg9+n0ACosLNTXv/51nXfeeZo6dar+9Kc/qaamRn/4wx86XL+4uFi1tbXh2/79+zt7SgCAHqjLrw5IS0vT2WefrV27dnX4eCAQUCAQ6OppAAB6mC7/P6Bjx45p9+7dysnJ6eqhAAC9SKcH0N13363169dr7969evPNN3XdddfJ7/fr5ptv7uyhAAC9WKf/Ce7AgQO6+eabVV1drQEDBuiSSy7Rpk2bNGDAgM4eCgDQi3V6AK1cubKzv2WPY4Lemnfaqht/lnWN8ds3XYxNbLWukaSac+0PoOM/st/lWtOsS+Rrs6+RpJYU+4aabUn24wzrZ99hdd/Z/ewH8ijo4bRslH2/XbUn2m/v4NiOr6g9neh3k61rJCkUsJ/f4S/Z1yQ9b10iGW8NVnsSesEBAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBNd/oF0fVI3NQGsz/Nb1/ja7BulmpB980RJGnZ2pXXNvn8Psq4JedhLoz0+Jy/aE+33h0MN9h1M/c324zRme9sOfi/9aT28LJoy7YtGZh62rvlnooeOsZIS99v/jt40ttHTWGcijoAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBN2we7BgwL7GRNt3F87tX2s/kCS/L2RdE4y1HyfuiH1HZ0/dnD3WeenWfbQ+wbompp/9dog/7K1zezDOfqzWZPtxQjH286tvtX9hxAytt66RpPj37J9USnqd/UA+D13Lu6krf1fiCAgA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnKAZaQ/mpXFnVFKbdU1BSrX9QJKqWxKta2LqPTQWbbEuUVS7fY0ktcfb14Ri7ZtC9ktstq4J1tlv71CMhyaXknxB+5roJvua5lz7hrbG2D+nkZkHrWskqTKYZF3T0m7/tpo6MNe6pv3AR9Y1PQ1HQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBM1Ie7D2JPsml4F4+2akydH2jTEl6WBTsnVNMN7+ObW32Tef9NkPI0kKHLWvMQH7hpr+KPsaD/1BZfweiiRFtdrXtNv3SlVclf1b0KixldY1l6T8y7pGkp46epZ1TW2zfRfhxlGp1jWxNCMFAMAbAggA4IR1AG3YsEFXX321cnNz5fP5tGrVqojHjTF64IEHlJOTo/j4eE2ZMkU7d+7srPkCAPoI6wBqaGjQmDFjtGzZsg4fX7JkiR577DE99dRT2rx5sxITEzV16lQ1N3s7zwAA6JuszwAWFhaqsLCww8eMMXr00Uf1ox/9SNdee60k6Xe/+52ysrK0atUq3XTTTZ9vtgCAPqNTzwGVl5erqqpKU6ZMCS9LTU3VuHHjtHHjxg5rWlpaVFdXF3EDAPR9nRpAVVVVkqSsrKyI5VlZWeHHPqmkpESpqanhW15eXmdOCQDQQzm/Cq64uFi1tbXh2/79+11PCQDQDTo1gLKzsyVJBw8ejFh+8ODB8GOfFAgElJKSEnEDAPR9nRpABQUFys7OVllZWXhZXV2dNm/erPHjx3fmUACAXs76Krhjx45p165d4fvl5eXatm2b0tPTNXjwYM2fP18/+clPNHz4cBUUFOj+++9Xbm6upk+f3pnzBgD0ctYBtGXLFl166aXh+wsXLpQkzZ49W6Wlpbr33nvV0NCguXPnqqamRpdcconWrFmjuLi4zps1AKDXsw6gSZMmyZhTd3r0+Xx66KGH9NBDD32uifU1UR4CuD3BvqNmUqx9M9J4v32NJNW12D+nUIz9cwrG2Tcj9dJUVJICtfbz89fbd/w81hywrrFvcSnF1Hvrytqaar/NQ34P267FfpwjrfZdT8cEvDXubOln/7NtbrD/SdUNtm/KmmFd0fM4vwoOAHBmIoAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAn7FqzwxIwaZl+TELSuSYlrsa450pJkXSNJ8TH2XbR9Qfvuxz77zaAobw2+PTEeOnw3eeiYHG//o1Uoxr5GkmI9dAUPxnr42Xpo1l3TEm9dc05sgv1Aklo8dAXXMfuN3jTAwzh9AEdAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEzUi7i6/nNhvMiav1VLe7LqOTZ9J5vDbhbOpv/zuZr82+o6aHHpxqT/CwD3kZSFKUh0Iv29zvocFqRlyDdc2B9mP2A0mq/UqzdU3sHvtmqe1JHn9QvRxHQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBM1Iu0lTtn2DQvlC1iXZiXXWNZXNqdY1kpTupSmk30vTRfsmnFHtHoaRFFtnP79gctC6JjnZvsllzLE465q2RI9NcD38mEIB+yJ/i/38Gts9dpr1IGeAfaPe+rfsX+v1Q+xf630BR0AAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4ATNSLtJe5x900VfjH2DwkR/q3VNvL/NukaSdjdnWNf4gh6aY3r5NclLz1NJIQ99LqMa7SeYEGu/zdu78dXqoQ+u/E32P9uQh+cU67dv/loRDNgPJCk9vtG65pj99GTiaEYKAEC3IYAAAE5YB9CGDRt09dVXKzc3Vz6fT6tWrYp4fM6cOfL5fBG3adOmddZ8AQB9hHUANTQ0aMyYMVq2bNkp15k2bZoqKyvDt+eee+5zTRIA0PdYnwIsLCxUYWHhadcJBALKzs72PCkAQN/XJeeA1q1bp8zMTI0YMUK33367qqurT7luS0uL6urqIm4AgL6v0wNo2rRp+t3vfqeysjL9/Oc/1/r161VYWKhgsONrE0tKSpSamhq+5eXldfaUAAA9UKf/Z8FNN90U/nr06NE677zzNHToUK1bt06TJ08+af3i4mItXLgwfL+uro4QAoAzQJdfhj1kyBBlZGRo165dHT4eCASUkpIScQMA9H1dHkAHDhxQdXW1cnJyunooAEAvYv0nuGPHjkUczZSXl2vbtm1KT09Xenq6Fi9erOuvv17Z2dnavXu37r33Xg0bNkxTp07t1IkDAHo36wDasmWLLr300vD9E+dvZs+erSeffFLbt2/Xb3/7W9XU1Cg3N1dXXHGFfvzjHysQ8NaLCQDQN1kH0KRJk2TMqTs9/uUvf/lcE+qrmvvZ/7XTtNnXtHjo7hgd5aF7oqSEGPvGp1H2JfJ56ZXqoeepJMXWe2kKaT9YXHS7dU2dh0ap/hZvXVm9NCONbrKvafVwyvefh7Osa9py/PYDSYrz0KjXy7aTlya9fQC94AAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOBEp38kNzrW0s++262vyb6Db2vIvmZgjIc2xpL2q591TZSHrr+hWOsSz9oS7H8nCyXbd7ZuaLV/UibKftsFPX4Kipcu2lEeupZ76Y7e3GLfFrwmlGA/kKTk6Bbrmph6Dx3I/fY1fo+fHh2sq/NU1xU4AgIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJ2hG2k2aM+ybDfra7JtPHmuz7z4Z4wta10jS3up065rAv+3H8dJQ03j81crf5qGRpIcGq/6okHWN8dAg1Ot28NJY1EsD0+gY+23XVGO/Q7QZb291BQlHrGvese+V6okvw/71J0miGSkA4ExHAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACdoRtpNTEz3NCOta4mzronz0nlSUnNlonVNVLynoax5aYwpScFY+20e1Wz/e1xuUq11zYH2AdY1bYn2z0eSotq9bT9b/hb7mthD9m9br9acaz+QpHMSK6xrjN/DQD777d2Wk+ZhIMm3x1NZl+AICADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcoBlpNwnFhaxrYpq8dDW01xyK8VQX3WD/+0v8Yfumi02Z9g012xO8NeGMOWb/c5KHkn6xTdY1+zy8Wr02FTUefjX1UtOWZF8TW2f/sz3U4mEgSVPSjlrXhGI8NLSts//htqR7O36wb1fcdTgCAgA4QQABAJywCqCSkhJdcMEFSk5OVmZmpqZPn64dO3ZErNPc3KyioiL1799fSUlJuv7663Xw4MFOnTQAoPezCqD169erqKhImzZt0tq1a9XW1qYrrrhCDQ0N4XUWLFigl156Sc8//7zWr1+viooKzZgxo9MnDgDo3azOfK1ZsybifmlpqTIzM7V161ZNmDBBtbW1evrpp/Xss8/qsssukyQtX75c55xzjjZt2qSLLrqo82YOAOjVPtc5oNra4x8rnJ6eLknaunWr2traNGXKlPA6I0eO1ODBg7Vx48YOv0dLS4vq6uoibgCAvs9zAIVCIc2fP18XX3yxRo0aJUmqqqpSbGys0tLSItbNyspSVVVVh9+npKREqamp4VteXp7XKQEAehHPAVRUVKT33ntPK1eu/FwTKC4uVm1tbfi2f//+z/X9AAC9g6d/RJ03b55efvllbdiwQYMGDQovz87OVmtrq2pqaiKOgg4ePKjs7OwOv1cgEFAgEPAyDQBAL2Z1BGSM0bx58/Tiiy/qtddeU0FBQcTjY8eOVUxMjMrKysLLduzYoX379mn8+PGdM2MAQJ9gdQRUVFSkZ599VqtXr1ZycnL4vE5qaqri4+OVmpqq73znO1q4cKHS09OVkpKiO+64Q+PHj+cKOABABKsAevLJJyVJkyZNili+fPlyzZkzR5L0y1/+UlFRUbr++uvV0tKiqVOn6oknnuiUyQIA+g6rADLm0xsbxsXFadmyZVq2bJnnSfV0/gEDrGti+zVb10RV2TdQrGu2P5+WGt1oXSNJxkO/z5CHs46+oH1NVKt9jVdRbfYborIpxbrGS7NPL40xJSm6zb6JqYmyH8vLrhflYW6ZgWP2A8lbo962RE9DeRiHZqQAAHhCAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAE54+EfVMF8rPsq7pl2zf9je0176tbsbEWuuaI23J1jWSlLzXviYUa98x2d9iP05Uu33HZK+8dKluC/mta7x0tvbSOVry9pyim+zHakuyf04xHhpbt3l5QpKS/U3WNUEPH/Ac3WC/HYL2jbp7HI6AAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJmpF60JBn3yS0qTVoXZPUaN/cMSnGvnPnkZYk6xrJWyPJ2Fr759SeaD9Oa4p9jSTFHbWfX1y1h4aaUfb7Q3N/6xIlVtjXSFKomxpdemnc6WVuh5u97ePdJRhvv98FA9728Z6EIyAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIJmpB4cy/Vb1/RLaLKuCbUk248T22hdc7Q1wbpGkqLtn5LaEzw0ULTv06ho+80gSfIF7QdL3W3fWHR0mn2X0H8l51vXGPtdVZLkC3mrsxXVZl/jZW6psc32RZKSo+zrQjH2+5DxcCgQjKMZKQAAnhBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACZqRetCaYl/T3G6/qaOj7ZsNxnjo1BgbZd9MU5KnJqHdpSnTW10o1r57Z1Sr/Tg3p222rnlh4PnWNcH93hrN+ps9NNT00Pg0utF+nLij9vtrdUuidY0k1YfirGtMjKehrAUD3TNOV+IICADgBAEEAHDCKoBKSkp0wQUXKDk5WZmZmZo+fbp27NgRsc6kSZPk8/kibrfddlunThoA0PtZBdD69etVVFSkTZs2ae3atWpra9MVV1yhhoaGiPVuvfVWVVZWhm9Llizp1EkDAHo/qzPja9asibhfWlqqzMxMbd26VRMmTAgvT0hIUHZ2dufMEADQJ32uc0C1tbWSpPT09IjlK1asUEZGhkaNGqXi4mI1Np7685FbWlpUV1cXcQMA9H2eL8MOhUKaP3++Lr74Yo0aNSq8fNasWcrPz1dubq62b9+u++67Tzt27NALL7zQ4fcpKSnR4sWLvU4DANBLeQ6goqIivffee3rjjTcils+dOzf89ejRo5WTk6PJkydr9+7dGjp06Enfp7i4WAsXLgzfr6urU15entdpAQB6CU8BNG/ePL388svasGGDBg0adNp1x40bJ0natWtXhwEUCAQUCPSB/6gCAFixCiBjjO644w69+OKLWrdunQoKCj61Ztu2bZKknJwcTxMEAPRNVgFUVFSkZ599VqtXr1ZycrKqqqokSampqYqPj9fu3bv17LPP6sorr1T//v21fft2LViwQBMmTNB5553XJU8AANA7WQXQk08+Ken4P5t+3PLlyzVnzhzFxsbq1Vdf1aOPPqqGhgbl5eXp+uuv149+9KNOmzAAoG+w/hPc6eTl5Wn9+vWfa0IAgDMD3bA9SDho38F3zlkbrWueTr3GuiYt5tT/c3Uqu+ozrGskqb7AvvO2jH2H77hq+5r0f3qYm6TWJPuxmvvb18za+h3rGv9O+87WXjpUS1Jrqv1zak2xf120ZrZb17R/YN9uOtvfZl0jSQP89dY1obxm65q8AUeta7R2gH1ND0MzUgCAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwgmakHqT/xr6xaOkN461rqie0Wte0eeg+aX7Q37pGkoZu2mRdE52dZV3TXnXQuga9g3/4EOua4M491jXvJX7FukaS9nzzLeuaYIv9a7A9ZH8skPjnf1jX9DQcAQEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACd6XC84Y4wkqV1tknE8mU4UbGixrgk1NVvXtBxrs65pb7cfR5Jk7MdSyL6/XbuXcdArmKD96yLoYX8ItnjbxxuPBa1rvLxu2z28P/Tk10W7js/txPv5qfjMp63RzQ4cOKC8vDzX0wAAfE779+/XoEGDTvl4jwugUCikiooKJScny+fzRTxWV1envLw87d+/XykpKY5m6B7b4Ti2w3Fsh+PYDsf1hO1gjFF9fb1yc3MVFXXqMz097k9wUVFRp01MSUpJSTmjd7AT2A7HsR2OYzscx3Y4zvV2SE1N/dR1uAgBAOAEAQQAcKJXBVAgENCiRYsUCARcT8UptsNxbIfj2A7HsR2O603bocddhAAAODP0qiMgAEDfQQABAJwggAAAThBAAAAnCCAAgBO9JoCWLVums846S3FxcRo3bpz+/ve/u55St3vwwQfl8/kibiNHjnQ9rS63YcMGXX311crNzZXP59OqVasiHjfG6IEHHlBOTo7i4+M1ZcoU7dy5081ku9CnbYc5c+actH9MmzbNzWS7SElJiS644AIlJycrMzNT06dP144dOyLWaW5uVlFRkfr376+kpCRdf/31OnjwoKMZd43Psh0mTZp00v5w2223OZpxx3pFAP3+97/XwoULtWjRIr311lsaM2aMpk6dqkOHDrmeWrc799xzVVlZGb698cYbrqfU5RoaGjRmzBgtW7asw8eXLFmixx57TE899ZQ2b96sxMRETZ06Vc3NHrt891Cfth0kadq0aRH7x3PPPdeNM+x669evV1FRkTZt2qS1a9eqra1NV1xxhRoaGsLrLFiwQC+99JKef/55rV+/XhUVFZoxY4bDWXe+z7IdJOnWW2+N2B+WLFniaManYHqBCy+80BQVFYXvB4NBk5uba0pKShzOqvstWrTIjBkzxvU0nJJkXnzxxfD9UChksrOzzSOPPBJeVlNTYwKBgHnuuecczLB7fHI7GGPM7NmzzbXXXutkPq4cOnTISDLr1683xhz/2cfExJjnn38+vM4///lPI8ls3LjR1TS73Ce3gzHGTJw40dx5553uJvUZ9PgjoNbWVm3dulVTpkwJL4uKitKUKVO0ceNGhzNzY+fOncrNzdWQIUP0jW98Q/v27XM9JafKy8tVVVUVsX+kpqZq3LhxZ+T+sW7dOmVmZmrEiBG6/fbbVV1d7XpKXaq2tlaSlJ6eLknaunWr2traIvaHkSNHavDgwX16f/jkdjhhxYoVysjI0KhRo1RcXKzGxkYX0zulHtcN+5OOHDmiYDCorKysiOVZWVn64IMPHM3KjXHjxqm0tFQjRoxQZWWlFi9erK9+9at67733lJyc7Hp6TlRVVUlSh/vHicfOFNOmTdOMGTNUUFCg3bt36wc/+IEKCwu1ceNG+f1+19PrdKFQSPPnz9fFF1+sUaNGSTq+P8TGxiotLS1i3b68P3S0HSRp1qxZys/PV25urrZv36777rtPO3bs0AsvvOBwtpF6fADh/xQWFoa/Pu+88zRu3Djl5+frD3/4g77zne84nBl6gptuuin89ejRo3Xeeedp6NChWrdunSZPnuxwZl2jqKhI77333hlxHvR0TrUd5s6dG/569OjRysnJ0eTJk7V7924NHTq0u6fZoR7/J7iMjAz5/f6TrmI5ePCgsrOzHc2qZ0hLS9PZZ5+tXbt2uZ6KMyf2AfaPkw0ZMkQZGRl9cv+YN2+eXn75Zb3++usRnx+WnZ2t1tZW1dTURKzfV/eHU22HjowbN06SetT+0OMDKDY2VmPHjlVZWVl4WSgUUllZmcaPH+9wZu4dO3ZMu3fvVk5OjuupOFNQUKDs7OyI/aOurk6bN28+4/ePAwcOqLq6uk/tH8YYzZs3Ty+++KJee+01FRQURDw+duxYxcTEROwPO3bs0L59+/rU/vBp26Ej27Ztk6SetT+4vgris1i5cqUJBAKmtLTUvP/++2bu3LkmLS3NVFVVuZ5at7rrrrvMunXrTHl5ufnb3/5mpkyZYjIyMsyhQ4dcT61L1dfXm7ffftu8/fbbRpJZunSpefvtt82HH35ojDHmZz/7mUlLSzOrV68227dvN9dee60pKCgwTU1NjmfeuU63Herr683dd99tNm7caMrLy82rr75qvvSlL5nhw4eb5uZm11PvNLfffrtJTU0169atM5WVleFbY2NjeJ3bbrvNDB482Lz22mtmy5YtZvz48Wb8+PEOZ935Pm077Nq1yzz00ENmy5Ytpry83KxevdoMGTLETJgwwfHMI/WKADLGmMcff9wMHjzYxMbGmgsvvNBs2rTJ9ZS63Y033mhycnJMbGysGThwoLnxxhvNrl27XE+ry73++utG0km32bNnG2OOX4p9//33m6ysLBMIBMzkyZPNjh073E66C5xuOzQ2NporrrjCDBgwwMTExJj8/Hxz66239rlf0jp6/pLM8uXLw+s0NTWZ73//+6Zfv34mISHBXHfddaaystLdpLvAp22Hffv2mQkTJpj09HQTCATMsGHDzD333GNqa2vdTvwT+DwgAIATPf4cEACgbyKAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACf+PxpqhI3POYIeAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_1 = nn.Sequential(\n",
        "   nn.Conv2d(1, 8, kernel_size = 3),\n",
        "   nn.BatchNorm2d(8),\n",
        "   nn.ReLU(),\n",
        "   nn.Flatten(),\n",
        "   nn.Linear(5408, 2048),\n",
        "   nn.ReLU(),\n",
        "   nn.Linear(2048, 256),\n",
        "   nn.Dropout(0.5),\n",
        "   nn.ReLU(),\n",
        "   nn.Linear(256, 10),\n",
        "   nn.LogSoftmax(dim=-1)\n",
        ")\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea7699eb-55aa-4f33-8a6a-008e7d5f4dda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU()\n",
              "  (3): Flatten(start_dim=1, end_dim=-1)\n",
              "  (4): Linear(in_features=5408, out_features=2048, bias=True)\n",
              "  (5): Dropout(p=0.3, inplace=False)\n",
              "  (6): ReLU()\n",
              "  (7): Linear(in_features=2048, out_features=256, bias=True)\n",
              "  (8): ReLU()\n",
              "  (9): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (10): LogSoftmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "c9ea58a3-83ae-4c65-a41f-50f0d4889754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd7f3bbd-b802-427f-bace-efef17fc6ea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-30-ca369b01b48c>\", line 28, in <cell line: 0>\n",
            "    plt.show()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\", line 614, in show\n",
            "    return _get_backend_mod().show(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib_inline/backend_inline.py\", line 90, in show\n",
            "    display(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\", line 320, in display\n",
            "    format_dict, md_dict = format(obj, include=include, exclude=exclude)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\", line 180, in format\n",
            "    data = formatter(obj)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"<decorator-gen-2>\", line 2, in __call__\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\", line 224, in catch_format_error\n",
            "    r = method(self, *args, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\", line 341, in __call__\n",
            "    return printer(obj)\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py\", line 151, in print_figure\n",
            "    fig.canvas.print_figure(bytes_io, **kw)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/backend_bases.py\", line 2155, in print_figure\n",
            "    self.figure.draw(renderer)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\", line 94, in draw_wrapper\n",
            "    result = draw(artist, renderer, *args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\", line 71, in draw_wrapper\n",
            "    return draw(artist, renderer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/figure.py\", line 3257, in draw\n",
            "    mimage._draw_list_compositing_images(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\", line 134, in _draw_list_compositing_images\n",
            "    a.draw(renderer)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\", line 71, in draw_wrapper\n",
            "    return draw(artist, renderer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\", line 3181, in draw\n",
            "    mimage._draw_list_compositing_images(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\", line 134, in _draw_list_compositing_images\n",
            "    a.draw(renderer)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\", line 71, in draw_wrapper\n",
            "    return draw(artist, renderer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/axis.py\", line 1419, in draw\n",
            "    tick.draw(renderer)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\", line 71, in draw_wrapper\n",
            "    return draw(artist, renderer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/axis.py\", line 276, in draw\n",
            "    artist.draw(renderer)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\", line 71, in draw_wrapper\n",
            "    return draw(artist, renderer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/lines.py\", line 847, in draw\n",
            "    .get_transformed_points_and_affine())\n",
            "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 2787, in get_transformed_points_and_affine\n",
            "    self._revalidate()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 2775, in _revalidate\n",
            "    self._transform.transform_non_affine(self._path.vertices),\n",
            "                                         ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/path.py\", line 211, in vertices\n",
            "    @property\n",
            "    \n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1667, in getframeinfo\n",
            "    positions = _get_code_position_from_tb(frame)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1649, in _get_code_position_from_tb\n",
            "    return _get_code_position(code, instruction_index)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1656, in _get_code_position\n",
            "    return next(itertools.islice(positions_gen, instruction_index // 2, None))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-ca369b01b48c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_backend_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib_inline/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             display(\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2154\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_draw_disabled\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnullcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3256\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3257\u001b[0;31m                 mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3258\u001b[0m                     renderer, self, artists, self.suppressComposite)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3181\u001b[0;31m         mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3182\u001b[0m             renderer, self, artists, self.get_figure(root=True).suppressComposite)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1419\u001b[0;31m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    275\u001b[0m                        self.label1, self.label2]:\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 tpath, affine = (self._get_transformed_path()\n\u001b[0;32m--> 847\u001b[0;31m                                  .get_transformed_points_and_affine())\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mget_transformed_points_and_affine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2786\u001b[0m         \"\"\"\n\u001b[0;32m-> 2787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_revalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformed_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36m_revalidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2774\u001b[0m                 Path._fast_from_codes_and_verts(\n\u001b[0;32m-> 2775\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_non_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2776\u001b[0m                     None, self._path)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/path.py\u001b[0m in \u001b[0;36mvertices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvertices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "l = nn.NLLLoss()\n",
        "optim = torch.optim.Adam(model_task_1.parameters(), lr = 0.001, weight_decay=0.0002)\n",
        "#sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, 'min', factor=0.8, patience=5)\n",
        "losses = []\n",
        "losses2 = []\n",
        "i = 0\n",
        "num_epochs = 10\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  for imgs, trgs in train_data_loader:\n",
        "    optim.zero_grad()\n",
        "    pred = model_task_1(imgs.to(device))\n",
        "    loss = l(pred, trgs.to(device))\n",
        "    losses.append(loss.to('cpu'))\n",
        "    '''with torch.no_grad():\n",
        "      for _imgs, _trgs in test_data_loader:\n",
        "        losses2.append(l(model_task_1(_imgs.to(device)), _trgs.to(device)).to('cpu'))\n",
        "        break'''\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "  if(i % 5 == 0):\n",
        "    with torch.no_grad():\n",
        "      #sched.step(get_accuracy(model_task_1, test_data_loader))\n",
        "      clear_output(True)\n",
        "      plt.plot(losses)\n",
        "      plt.plot(losses2)\n",
        "      plt.show()\n",
        "      print(i)\n",
        "  i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f27937-1e03-4f03-cff7-99f7ae0ee2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.9853\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932dec0d-cf4e-4816-bcf3-285333029ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8674\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAIrURCEgSq_",
        "outputId": "ba780b68-2d59-4866-bf22-14b064d10d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Train accuracy is below 0.885 threshold",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c0a27eab887f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtest_acc_task_1\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.885\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Train accuracy is below 0.885 threshold\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m assert (\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_acc_task_1\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.905\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\"\n",
            "\u001b[0;31mAssertionError\u001b[0m: Train accuracy is below 0.885 threshold"
          ]
        }
      ],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDxhQad3soIo"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bVNI8IZsoIp"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igh5mRdssoIp"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "facelv_1.13+cu117",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}